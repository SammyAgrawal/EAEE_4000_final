{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd7c4dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samart/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import stable_baselines3\n",
    "from stable_baselines3 import PPO, DDPG, A2C\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray\n",
    "\n",
    "import random\n",
    "import math\n",
    "from functools import partial\n",
    "from scipy.stats import gamma\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import fair\n",
    "from fair.io import read_properties\n",
    "from fair.interface import fill, initialise\n",
    "from fair.earth_params import seconds_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd571876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2104797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 'ssp245' #scenario to use as baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a32ee9",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fa4054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  erf\n",
      "year                 \n",
      "1750.000000  0.246406\n",
      "1750.083333  0.246408\n",
      "1750.166667  0.246409\n",
      "1750.250000  0.246410\n",
      "1750.333333  0.246411\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>run</th>\n",
       "      <th>conv</th>\n",
       "      <th>nit</th>\n",
       "      <th>gamma</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>kappa1</th>\n",
       "      <th>kappa2</th>\n",
       "      <th>kappa3</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>sigma_eta</th>\n",
       "      <th>sigma_xi</th>\n",
       "      <th>F_4xCO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAMS-CSM1-0</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>True</td>\n",
       "      <td>4809</td>\n",
       "      <td>28.239872</td>\n",
       "      <td>2.632439</td>\n",
       "      <td>9.262195</td>\n",
       "      <td>52.927697</td>\n",
       "      <td>1.876254</td>\n",
       "      <td>5.153591</td>\n",
       "      <td>0.643546</td>\n",
       "      <td>1.285458</td>\n",
       "      <td>2.690512</td>\n",
       "      <td>0.439493</td>\n",
       "      <td>8.870602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GISS-E2-2-G</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>True</td>\n",
       "      <td>3965</td>\n",
       "      <td>2.385368</td>\n",
       "      <td>3.601142</td>\n",
       "      <td>11.333337</td>\n",
       "      <td>313.520678</td>\n",
       "      <td>1.972359</td>\n",
       "      <td>1.922481</td>\n",
       "      <td>0.631276</td>\n",
       "      <td>0.443575</td>\n",
       "      <td>0.544189</td>\n",
       "      <td>0.535407</td>\n",
       "      <td>8.035197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model       run  conv   nit      gamma        C1         C2  \\\n",
       "0  CAMS-CSM1-0  r1i1p1f1  True  4809  28.239872  2.632439   9.262195   \n",
       "1  GISS-E2-2-G  r1i1p1f1  True  3965   2.385368  3.601142  11.333337   \n",
       "\n",
       "           C3    kappa1    kappa2    kappa3   epsilon  sigma_eta  sigma_xi  \\\n",
       "0   52.927697  1.876254  5.153591  0.643546  1.285458   2.690512  0.439493   \n",
       "1  313.520678  1.972359  1.922481  0.631276  0.443575   0.544189  0.535407   \n",
       "\n",
       "    F_4xCO2  \n",
       "0  8.870602  \n",
       "1  8.035197  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/example_github_data/'\n",
    "volcano_df = pd.read_csv(os.path.join(data_path, 'volcano_forcing_data.csv'), index_col='year').drop(['Unnamed: 0'], axis=1)\n",
    "print(volcano_df.head())\n",
    "\n",
    "climate_df = pd.read_csv(os.path.join(data_path, 'climate_models_data.csv')).drop(['Unnamed: 0'], axis=1)\n",
    "climate_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c1c3d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssp(scenario, category='emissions'):\n",
    "    assert (category=='emissions' or category=='concentrations')\n",
    "    path = '../data/fair_ssp_scenarios/' + scenario + \"_\" + category + \".csv\"\n",
    "    ssp = pd.read_csv(path).drop(['Unnamed: 0'], axis=1)\n",
    "    ssp['Year'] = ssp['Year'].astype(np.int16)\n",
    "    return(ssp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5d95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xequals(d1, d2):\n",
    "    assert type(d1) == type(d2), \"Type mismatch\"\n",
    "    if(type(d1) == xarray.core.dataset.Dataset):\n",
    "        a = np.nan_to_num(d1.to_array())\n",
    "        b = np.nan_to_num(d2.to_array())\n",
    "    elif(type(d1) == xarray.core.dataarray.DataArray):\n",
    "        a = np.nan_to_num(d1.data)\n",
    "        b = np.nan_to_num(d2.data)\n",
    "    res = np.array_equal(a, b)\n",
    "    if not res:\n",
    "        return(res, np.where(a!=b, 1, 0))\n",
    "    return(res)\n",
    "\n",
    "def models_equal(f1, f2):\n",
    "    \n",
    "    #equal if all attributes same values\n",
    "    \n",
    "    if(xequals(f1.species_configs, f2.species_configs) and xequals(f1.climate_configs, f2.climate_configs)):\n",
    "        if(xequals(f1.stochastic_forcing, f2.stochastic_forcing) and xequals(f1.emissions, f2.emissions) and xequals(f1.forcing_sum, f2.forcing_sum)):\n",
    "            if(xequals(f1.concentration, f2.concentration) and xequals(f1.forcing, f2.forcing) and xequals(f1.temperature, f2.temperature)):\n",
    "                if(xequals(f2.airborne_emissions, f1.airborne_emissions) and xequals(f2.ocean_heat_content_change, f1.ocean_heat_content_change)):\n",
    "                    return(xequals(f2.toa_imbalance, f1.toa_imbalance) and xequals(f2.cumulative_emissions, f1.cumulative_emissions))\n",
    "                else:\n",
    "                    print('d')\n",
    "            else:\n",
    "                print('c')\n",
    "        else:\n",
    "            print('b')\n",
    "    else:\n",
    "        print('a')\n",
    "    return(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e413ed",
   "metadata": {},
   "source": [
    "# Reward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5612618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#state is [cur_temp, emit_c, emit_s, conc_c, forcing]\n",
    "\n",
    "def simple_reward(old_state, state, year, GDP, GDP_cost, cur_fease):\n",
    "    # positive reward for temp decrease\n",
    "    # negative cliff if warming exceeds 2ยบ\n",
    "    cur_temp = state[0]\n",
    "    if cur_temp > 2:\n",
    "        return -100\n",
    "    return (old_state[0] - cur_temp) # punish \n",
    "\n",
    "def simple_temp_reward(old_state, state, year, GDP, GDP_cost, cur_fease):\n",
    "    # positive reward for temp under 1.5 goal\n",
    "    cur_temp = state[0]\n",
    "    if cur_temp > 3.5:\n",
    "        return -100\n",
    "    return 100*(1.5 - cur_temp)\n",
    "\n",
    "def conc_reward(old_state, state, year, GDP, GDP_cost, cur_fease):\n",
    "    # positive reward for decreased concentration\n",
    "    cur_temp = state[0]\n",
    "    if cur_temp > 2:\n",
    "        return -100\n",
    "    return old_state[3] - state[3] # punish for increase in co2 concentration\n",
    "\n",
    "def carbon_cost_reward(old_state, state, year, GDP, GDP_cost, cur_fease):\n",
    "    # impose a cost for each GtC emitted\n",
    "    cur_temp, cur_emit = state[0], state[1]\n",
    "    if cur_temp > 2:\n",
    "        return -100\n",
    "    return -cur_emit\n",
    "\n",
    "#state is [cur_temp, emit_c, emit_s, conc_c, forcing]\n",
    "\n",
    "def carbon_cost_GDP_reward(old_state, state, year, GDP, GDP_cost, cur_fease):\n",
    "    cur_temp = state[0]\n",
    "    reward = 100 * cur_fease\n",
    "    alpha = 1000 if cur_temp > 2 else 200\n",
    "    reward += alpha * (2-cur_temp)  \n",
    "    reward += GDP/1e12\n",
    "    reward -= GDP_cost/1e11\n",
    "    \n",
    "    if(abs(reward) > 7000):\n",
    "        print(\"Noteworthy reward: \", reward)\n",
    "        print([old_state, state, year, GDP, GDP_cost, cur_fease]) \n",
    "        print()\n",
    "        \n",
    "    return reward\n",
    "\n",
    "def temp_emit_reward(old_state, state, year, GDP, GDP_cost, cur_fease):\n",
    "    # positive reward for keeping the temp under 1.5\n",
    "    # negative reward for amount of emissions reduction\n",
    "    # positive cliff for success at the end of the trial\n",
    "    # w could indicate cost\n",
    "    \n",
    "    cur_temp, cur_emit_c = state[0], state[1]\n",
    "    if cur_temp > 2:\n",
    "        return -100\n",
    "    if year==2100 and temp<=1.5:\n",
    "        return 1000\n",
    "    temp = 10*(old_state[0] - cur_temp)\n",
    "    emit_decrease = old_state[1] - cur_emit_c # decrease in emissions\n",
    "    if emit_decrease>0:\n",
    "        return temp + emit_decrease\n",
    "    return temp\n",
    "\n",
    "\n",
    "def temp_emit_diff_reward(old_state, state, year, GDP, GDP_cost, cur_fease):\n",
    "    # positive reward for keeping the temp under 1.5\n",
    "    # negative reward for amount of emissions reduction\n",
    "    # (reduction compared to projected amount for that year)\n",
    "    # positive cliff for success at the end of the trial\n",
    "    # w could indicate cost of emissions\n",
    "    cur_temp, cur_emit = state[0], state[1]\n",
    "    if cur_temp > 2:\n",
    "        return -100\n",
    "    if year==2100 and cur_temp <=1.5:\n",
    "        return 100\n",
    "    curval = (year-2021)*0.6 + 36\n",
    "    temp_decrease = 10*(old_state[0] - cur_temp) #magnified decrease in temp\n",
    "    emit = curval - cur_emit\n",
    "    if emit>0:\n",
    "        return temp_decrease + emit\n",
    "    return temp_decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851b0e1",
   "metadata": {},
   "source": [
    "# Setup Environment and Econ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93c05a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 'ssp245' #scenario to use as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92ab1069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>CO2-fossil (GtC/yr)</th>\n",
       "      <th>CO2-landuse (GtC/yr)</th>\n",
       "      <th>CH4 (Mt/yr)</th>\n",
       "      <th>N2O (MtN2/yr)</th>\n",
       "      <th>SOx (MtS/yr)</th>\n",
       "      <th>CO (Mt/yr)</th>\n",
       "      <th>NMVOC (Mt/yr)</th>\n",
       "      <th>NOx (MtN/yr)</th>\n",
       "      <th>BC (Mt/yr)</th>\n",
       "      <th>...</th>\n",
       "      <th>Methyl chloroform (kt/yr)</th>\n",
       "      <th>HCFC22 (kt/yr)</th>\n",
       "      <th>HCFC141b (kt/yr)</th>\n",
       "      <th>HCFC142b (kt/yr)</th>\n",
       "      <th>Halon 1211 (kt/yr)</th>\n",
       "      <th>Halon 1202 (kt/yr)</th>\n",
       "      <th>Halon 1301 (kt/yr)</th>\n",
       "      <th>Halon 2401 (kt/yr)</th>\n",
       "      <th>CH3Br (kt/yr)</th>\n",
       "      <th>CH3Cl (kt/yr)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1765</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.106705</td>\n",
       "      <td>20.919155</td>\n",
       "      <td>0.113903</td>\n",
       "      <td>1.250025</td>\n",
       "      <td>352.932726</td>\n",
       "      <td>60.629458</td>\n",
       "      <td>3.878199</td>\n",
       "      <td>2.123600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.07293</td>\n",
       "      <td>4274.9668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1766</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.108668</td>\n",
       "      <td>20.853592</td>\n",
       "      <td>0.116055</td>\n",
       "      <td>1.243445</td>\n",
       "      <td>349.380645</td>\n",
       "      <td>59.858785</td>\n",
       "      <td>3.884896</td>\n",
       "      <td>2.110460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.07758</td>\n",
       "      <td>4275.2111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1767</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.110667</td>\n",
       "      <td>20.999179</td>\n",
       "      <td>0.118247</td>\n",
       "      <td>1.242612</td>\n",
       "      <td>349.616099</td>\n",
       "      <td>59.891027</td>\n",
       "      <td>3.880520</td>\n",
       "      <td>2.112461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.08566</td>\n",
       "      <td>4275.6359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1768</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.112703</td>\n",
       "      <td>21.659452</td>\n",
       "      <td>0.120481</td>\n",
       "      <td>1.293980</td>\n",
       "      <td>362.653685</td>\n",
       "      <td>62.365826</td>\n",
       "      <td>4.039050</td>\n",
       "      <td>2.183132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.04673</td>\n",
       "      <td>4273.5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1769</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.114777</td>\n",
       "      <td>21.496335</td>\n",
       "      <td>0.122758</td>\n",
       "      <td>1.272649</td>\n",
       "      <td>355.025419</td>\n",
       "      <td>60.950404</td>\n",
       "      <td>3.914664</td>\n",
       "      <td>2.137634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.07670</td>\n",
       "      <td>4275.1650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows ร 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  CO2-fossil (GtC/yr)  CO2-landuse (GtC/yr)  CH4 (Mt/yr)  \\\n",
       "0  1765             0.003046              0.106705    20.919155   \n",
       "1  1766             0.003396              0.108668    20.853592   \n",
       "2  1767             0.003397              0.110667    20.999179   \n",
       "3  1768             0.003398              0.112703    21.659452   \n",
       "4  1769             0.003400              0.114777    21.496335   \n",
       "\n",
       "   N2O (MtN2/yr)  SOx (MtS/yr)  CO (Mt/yr)  NMVOC (Mt/yr)  NOx (MtN/yr)  \\\n",
       "0       0.113903      1.250025  352.932726      60.629458      3.878199   \n",
       "1       0.116055      1.243445  349.380645      59.858785      3.884896   \n",
       "2       0.118247      1.242612  349.616099      59.891027      3.880520   \n",
       "3       0.120481      1.293980  362.653685      62.365826      4.039050   \n",
       "4       0.122758      1.272649  355.025419      60.950404      3.914664   \n",
       "\n",
       "   BC (Mt/yr)  ...  Methyl chloroform (kt/yr)  HCFC22 (kt/yr)  \\\n",
       "0    2.123600  ...                        0.0             0.0   \n",
       "1    2.110460  ...                        0.0             0.0   \n",
       "2    2.112461  ...                        0.0             0.0   \n",
       "3    2.183132  ...                        0.0             0.0   \n",
       "4    2.137634  ...                        0.0             0.0   \n",
       "\n",
       "   HCFC141b (kt/yr)  HCFC142b (kt/yr)  Halon 1211 (kt/yr)  Halon 1202 (kt/yr)  \\\n",
       "0               0.0               0.0            0.007723                 0.0   \n",
       "1               0.0               0.0            0.007723                 0.0   \n",
       "2               0.0               0.0            0.007723                 0.0   \n",
       "3               0.0               0.0            0.007723                 0.0   \n",
       "4               0.0               0.0            0.007723                 0.0   \n",
       "\n",
       "   Halon 1301 (kt/yr)  Halon 2401 (kt/yr)  CH3Br (kt/yr)  CH3Cl (kt/yr)  \n",
       "0                 0.0                 0.0      105.07293      4274.9668  \n",
       "1                 0.0                 0.0      105.07758      4275.2111  \n",
       "2                 0.0                 0.0      105.08566      4275.6359  \n",
       "3                 0.0                 0.0      105.04673      4273.5893  \n",
       "4                 0.0                 0.0      105.07670      4275.1650  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssp_df = ssp(scenario)\n",
    "plt.plot(ssp_df[ssp_df['Year'] < 2105]['Year'], ssp_df[ssp_df['Year'] < 2105]['CO2-fossil (GtC/yr)'])\n",
    "plt.show()\n",
    "ssp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "031fcf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736\n"
     ]
    }
   ],
   "source": [
    "current_year = 2023\n",
    "end_year = 2100\n",
    "\n",
    "size = ssp_df.shape[0]\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4db12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Economic parameters\n",
    "beta = 1.03 # estimated GDP growth rate over the year\n",
    "epsilon = 147.0 # USD/GJ\n",
    "rho = 2.0 # 1\n",
    "sigma = 4e12 # GJ\n",
    "tau_S = 65.0 # yr\n",
    "\n",
    "# cost to lower emissions by 1 GtC\n",
    "GtC_reduce_cost = 6e11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2795c34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cost model for SAI\n",
    "cost_per_MT = 1000 * 1e6 # cost per ton * 10^6 tons / Mt\n",
    "airplane_construction_cost = 1e8 # construction of additional airplane\n",
    "cost_per_year_deployed = 12 * 8e5 # annual lease rate = 12 * monthly\n",
    "\n",
    "payload_per_year_tons = 20 * 5  * 330 # tons/run * runs / day * operating days/year\n",
    "annual_delivery_capacity = payload_per_year_tons / 1e6 # how much sulfur a single plane can emit in a year\n",
    "annual_delivery_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8b99147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup economic variables to be updated throughout run\n",
    "\n",
    "Y = pd.Series(data=np.zeros(size), index=ssp_df['Year']) #global GDP\n",
    "Y_cost = pd.Series(data=np.zeros(size), index=ssp_df['Year']) #cost of climate change\n",
    "S = pd.Series(data=np.zeros(size), index=ssp_df['Year']) #renewable knowledge stock\n",
    "\n",
    "S.loc[:current_year-1] = 5e11 #GJ\n",
    "Y.loc[:current_year-1] = 9e13 #USD/a\n",
    "Y_cost.loc[:current_year-1] = 100*1e9 #USD/a\n",
    "\n",
    "S[current_year] = 5e11 #GJ\n",
    "Y[current_year] = 9.2e13 #USD/a\n",
    "Y_cost[current_year] = 100*1e9 #USD/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afc389e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic model\n",
    "species, properties = read_properties()\n",
    "averages = climate_df.drop_duplicates(subset=['model'], keep='first').mean(numeric_only=True)\n",
    "\n",
    "def setup_model(end_year=2105, scenario='ssp245', timesteps_per_year=1):\n",
    "    \n",
    "    # consider fiddling with sulfur properties since forcing seems weak and f.forcing does not include sulfur\n",
    "    \n",
    "    f = fair.FAIR(ghg_method= 'meinshausen2020', ch4_method='thornhill2021')\n",
    "    f.define_time(1750, end_year, 1/timesteps_per_year) #timepoints, timebounds\n",
    "    f.define_scenarios([scenario])\n",
    "    f.define_configs(['default', 'intervention'])\n",
    "    f.define_species(species, properties)\n",
    "    f.timesteps_per_year = timesteps_per_year\n",
    "    f.allocate()\n",
    "\n",
    "    # fill species configs using default values\n",
    "    f.fill_species_configs()\n",
    "    fill(f.species_configs['unperturbed_lifetime'], 10.8537568, specie='CH4')\n",
    "    fill(f.species_configs['baseline_emissions'], 19.01978312, specie='CH4')\n",
    "    fill(f.species_configs['baseline_emissions'], 0.08602230754, specie='N2O')\n",
    "\n",
    "    # Use climate_df for climate configs. take the average of the first runs of all models to obtain climate params\n",
    "    fill(f.climate_configs['ocean_heat_capacity'], averages.loc['C1':'C3'].values)\n",
    "    fill(f.climate_configs['ocean_heat_transfer'], averages.loc['kappa1':'kappa3'].values)\n",
    "    fill(f.climate_configs['deep_ocean_efficacy'], averages['epsilon'])\n",
    "    fill(f.climate_configs['gamma_autocorrelation'], averages['gamma'])\n",
    "    fill(f.climate_configs['sigma_eta'], averages['sigma_eta'])\n",
    "    fill(f.climate_configs['sigma_xi'], averages['sigma_xi'])\n",
    "    fill(f.climate_configs['stochastic_run'], True)\n",
    "    fill(f.climate_configs['use_seed'], True)\n",
    "    fill(f.climate_configs['seed'], 1355763)\n",
    "\n",
    "    f.fill_from_rcmip()\n",
    "\n",
    "    volcanic_forcing = np.zeros(f.timebounds.size)\n",
    "    volcanic_forcing[:timesteps_per_year*270] = volcano_df.iloc[::int(12/timesteps_per_year)].squeeze().values\n",
    "    fill(f.forcing, volcanic_forcing[:, None, None], specie='Volcanic')\n",
    "\n",
    "    initialise(f.concentration, f.species_configs['baseline_concentration'])\n",
    "    initialise(f.forcing, 0)\n",
    "    initialise(f.temperature, 0)\n",
    "    initialise(f.cumulative_emissions, 0)\n",
    "    initialise(f.airborne_emissions, 0)\n",
    "    \n",
    "    return(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0096da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"ssp245\"\n",
    "ref_model = setup_model(2105, scenario, 1)\n",
    "\n",
    "species_configs_ref = ref_model.species_configs.copy(deep=True)\n",
    "climate_configs_ref = ref_model.climate_configs.copy(deep=True)\n",
    "emissions_ref = ref_model.emissions.copy(deep=True)\n",
    "concentration_ref = ref_model.concentration.copy(deep=True)\n",
    "forcing_ref = ref_model.forcing.copy(deep=True)\n",
    "forcing_sum_ref = ref_model.forcing_sum.copy(deep=True)\n",
    "temperature_ref = ref_model.temperature.copy(deep=True)\n",
    "cumulative_emissions_ref = ref_model.cumulative_emissions.copy(deep=True)\n",
    "airborne_emissions_ref = ref_model.airborne_emissions.copy(deep=True)\n",
    "airborne_fraction_ref = ref_model.airborne_fraction.copy(deep=True)\n",
    "ocean_heat_content_change_ref = ref_model.ocean_heat_content_change.copy(deep=True)\n",
    "stochastic_forcing_ref = ref_model.stochastic_forcing.copy(deep=True)\n",
    "toa_imbalance_ref = ref_model.toa_imbalance.copy(deep=True)\n",
    "\n",
    "def model_reset_2(end_year=2105, timesteps_per_year=1): # faster than setup_model() because that function is too slow in practice\n",
    "    g = fair.FAIR(ghg_method= 'meinshausen2020', ch4_method='thornhill2021')\n",
    "    g.define_time(1750, end_year, 1) #timepoints, timebounds\n",
    "    g.define_scenarios([scenario])\n",
    "    g.define_configs(['default', 'intervention'])\n",
    "    g.define_species(species, properties)\n",
    "    g.allocate()\n",
    "    \n",
    "    g.timesteps_per_year = timesteps_per_year\n",
    "    g.species_configs = species_configs_ref\n",
    "    g.climate_configs = climate_configs_ref\n",
    "    g.emissions = emissions_ref\n",
    "    g.concentration = concentration_ref\n",
    "    g.forcing = forcing_ref\n",
    "    g.forcing_sum = forcing_sum_ref\n",
    "    g.temperature = temperature_ref\n",
    "    g.cumulative_emissions = cumulative_emissions_ref\n",
    "    g.airborne_emissions = airborne_emissions_ref\n",
    "    g.airborne_fraction = airborne_fraction_ref\n",
    "    g.ocean_heat_content_change = ocean_heat_content_change_ref\n",
    "    g.stochastic_forcing = stochastic_forcing_ref\n",
    "    g.toa_imbalance = toa_imbalance_ref\n",
    "    \n",
    "    return(g)\n",
    "\n",
    "def model_reset(end_year=2105, timesteps_per_year=1): # faster than setup_model() because that function is too slow in practice\n",
    "    g = fair.FAIR(ghg_method= 'meinshausen2020', ch4_method='thornhill2021')\n",
    "    g.define_time(1750, end_year, 1) #timepoints, timebounds\n",
    "    g.define_scenarios([scenario])\n",
    "    g.define_configs(['default', 'intervention'])\n",
    "    g.define_species(species, properties)\n",
    "    g.allocate()\n",
    "    \n",
    "    g.timesteps_per_year = timesteps_per_year\n",
    "    g.species_configs = ref_model.species_configs.copy(deep=True)\n",
    "    g.climate_configs = ref_model.climate_configs.copy(deep=True)\n",
    "    g.emissions = ref_model.emissions.copy(deep=True)\n",
    "    g.concentration = ref_model.concentration.copy(deep=True)\n",
    "    g.forcing = ref_model.forcing.copy(deep=True)\n",
    "    g.forcing_sum = ref_model.forcing_sum.copy(deep=True)\n",
    "    g.temperature = ref_model.temperature.copy(deep=True)\n",
    "    g.cumulative_emissions = ref_model.cumulative_emissions.copy(deep=True)\n",
    "    g.airborne_emissions = ref_model.airborne_emissions.copy(deep=True)\n",
    "    g.airborne_fraction = ref_model.airborne_fraction.copy(deep=True)\n",
    "    g.ocean_heat_content_change = ref_model.ocean_heat_content_change.copy(deep=True)\n",
    "    g.stochastic_forcing = ref_model.stochastic_forcing.copy(deep=True)\n",
    "    g.toa_imbalance = ref_model.toa_imbalance.copy(deep=True)\n",
    "    \n",
    "    return(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adf424bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.913731098175049, 'ms')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timing how long a reset takes using preloaded reference method\n",
    "\n",
    "tot = 0\n",
    "for i in range(100):\n",
    "    s = time.time()\n",
    "    a = model_reset()\n",
    "    tot += time.time() - s\n",
    "tot*10, \"ms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c29f4079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.091062068939209, 's')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timing how long a manual reset takes\n",
    "s = time.time()\n",
    "ref_model = setup_model(2105, scenario, 1)\n",
    "time.time() - s, 's'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776e112",
   "metadata": {},
   "source": [
    "# Creating Reinforcement Learning Environment using gym Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7d29558",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Simulator(gym.Env):\n",
    "    \n",
    "    def __init__(self, reward_mode=temp_emit_diff_reward, max_carbon=32, max_aerosol=100, clim_model=model_reset(),\n",
    "                current_year=2023, end_year=2104, scenario=scenario):\n",
    "        \n",
    "        # action space for the environment,\n",
    "        # the amount to increase or decrease emissions by\n",
    "        self.action_space = gym.spaces.Box(\n",
    "            low = np.array([-max_carbon, 0]).astype(np.float32),\n",
    "            high = np.array([max_carbon, max_aerosol]).astype(np.float32),\n",
    "        )\n",
    "        \n",
    "        self.model = clim_model \n",
    "        \n",
    "        # state space, [year, temp, co2_emit, sulfur_emit, co2_conc, forcing]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=np.array([-4, -200, -100, 0, -20.0]).astype(np.float32),\n",
    "            high=np.array([5, 200, 1000, 5000, 20.0]).astype(np.float32),\n",
    "        )\n",
    "        \n",
    "        self.reward_func = eval(reward_mode) if type(reward_mode)==str else reward_mode # specify the reward function to use\n",
    "        #self.scenario = scenario # not used currently; default rcmip data regardless\n",
    "        #self.scenario_emissions = ssp(scenario) # not used currently; default rcmip data regardless\n",
    "        self.state = None\n",
    "        \n",
    "        #for feasibility testing later\n",
    "        self.ssp_370 = ssp('ssp370')        \n",
    "        \n",
    "        # setup time bounding\n",
    "        self.start_year = current_year\n",
    "        self.end_year = end_year\n",
    "        self.time_increment = self.model.timesteps_per_year # gonna be 1\n",
    "        \n",
    "        # used for aerosol cost\n",
    "        self.airplanes_manufactured = 0\n",
    "    \n",
    "        \n",
    "    def reset(self):\n",
    "        \n",
    "        ## RESET ECONOMIC VARIABLES\n",
    "        \n",
    "        Y = pd.Series(data=np.zeros(size), index=ssp_df['Year']) #global GDP\n",
    "        Y_cost = pd.Series(data=np.zeros(size), index=ssp_df['Year']) #cost of climate change\n",
    "        S = pd.Series(data=np.zeros(size), index=ssp_df['Year']) #renewable knowledge stock\n",
    "\n",
    "        S.loc[:current_year-1] = 5e11 #GJ\n",
    "        Y.loc[:current_year-1] = 9e13 #USD/a\n",
    "        Y_cost.loc[:current_year-1] = 100*1e9 #USD/a\n",
    "\n",
    "        S[current_year] = 5e11 #GJ\n",
    "        Y[current_year] = 9.2e13 #USD/a\n",
    "        Y_cost[current_year] = 100*1e9 #USD/a\n",
    "        \n",
    "        ##             ##\n",
    "        \n",
    "        \n",
    "        ## reset- faster than calling setup_model() again\n",
    "        self.model = model_reset()\n",
    "        self.t = self.start_year - 1\n",
    "        \n",
    "        self.update_state(ref_model.emissions)\n",
    "        \n",
    "        return(self.state[self.model.configs[1]])                           \n",
    "    \n",
    "    \n",
    "    def update_state(self, emissions):\n",
    "        \n",
    "        self.forward_func(emissions)   \n",
    "        # state is [year, temp, co2_emit, sulfur_emit, co2_conc, forcing]   \n",
    "        # state refers to at the conclusion of year X, all variables. At end, we are at beginning of year X+1\n",
    "        self.state = {\n",
    "            'Year' : self.t,\n",
    "            self.model.configs[0] : np.array([\n",
    "                self.model.temperature.loc[self.t, self.model.scenarios[0], self.model.configs[0], 0].item(),\n",
    "                self.model.emissions.loc[self.t - self.time_increment/2, self.model.scenarios[0], self.model.configs[0], :][:2].sum().item(),\n",
    "                self.model.emissions.loc[self.t - self.time_increment/2, self.model.scenarios[0], self.model.configs[0], 'Sulfur'].item(),\n",
    "                self.model.concentration.loc[self.t, self.model.scenarios[0], self.model.configs[0], 'CO2'].item(),\n",
    "                self.model.forcing_sum.loc[self.t, self.model.scenarios[0], self.model.configs[0]].item()                \n",
    "            ], dtype=np.float32),\n",
    "            self.model.configs[1] : np.array([ \n",
    "                self.model.temperature.loc[self.t, self.model.scenarios[0], self.model.configs[1], 0].item(),\n",
    "                self.model.emissions.loc[self.t - self.time_increment/2, self.model.scenarios[0], self.model.configs[1], :][:2].sum().item(),\n",
    "                self.model.emissions.loc[self.t - self.time_increment/2, self.model.scenarios[0], self.model.configs[1], 'Sulfur'].item(),\n",
    "                self.model.concentration.loc[self.t, self.model.scenarios[0], self.model.configs[1], 'CO2'].item(),\n",
    "                self.model.forcing_sum.loc[self.t, self.model.scenarios[0], self.model.configs[1]].item()\n",
    "            ], dtype=np.float32)\n",
    "        }\n",
    "                               \n",
    "        self.t += self.time_increment\n",
    "    \n",
    "    def access_state(self):\n",
    "        return(self.state)\n",
    "    \n",
    "    def forward_func(self, emissions):\n",
    "\n",
    "        self.model = model_reset()\n",
    "        self.model.emissions = emissions.copy(deep=True)\n",
    "        \n",
    "        self.model.run(progress=False)\n",
    "    \n",
    "    def aerosol_cost(self, emit):\n",
    "        \n",
    "        # 3 factors: operating cost, construction cost, sulfur cost\n",
    "        num_airplanes = emit / annual_delivery_capacity # how many airplaces deployed\n",
    "        operational_cost = num_airplanes * cost_per_year_deployed\n",
    "        \n",
    "        num_new_airplaces = num_airplanes - self.airplanes_manufactured # number of new planes needed to service additional emissions\n",
    "        construction_cost = max(num_new_airplaces, 0) * airplane_construction_cost # cost of constructing new plances\n",
    "        \n",
    "        sulfur_cost = emit * cost_per_MT\n",
    "        \n",
    "        self.airplanes_manufactured = max(int(num_airplanes), int(self.airplanes_manufactured))\n",
    "        \n",
    "        return(sulfur_cost + construction_cost + operational_cost)\n",
    "        \n",
    "    \n",
    "    def render(self, mode=\"human\"):\n",
    "        if(self.state):\n",
    "            print(f\"Current Year: {self.state['Year']}\")\n",
    "            print(\"Without intervention:\")\n",
    "            config = self.model.configs[0]\n",
    "            # print the state [year, temp, co2_emit, sulfur_emit, co2_conc, forcing]\n",
    "            print(f'    Temperature anomaly: {self.state[config][0]}ยบC')\n",
    "            print(f'    CO2 emissions: {self.state[config][1]} GtC')\n",
    "            print(f'    Sulfur emissions: {self.state[config][2]} MtS')\n",
    "            print(f'    CO2 concentration: {self.state[config][3]} ppm')\n",
    "            print(f'    Radiative forcing: {self.state[config][4]} W/m2')\n",
    "            \n",
    "            print(\"\\nWith intervention:\")\n",
    "            config = self.model.configs[1]\n",
    "            # print the state [year, temp, co2_emit, sulfur_emit, co2_conc, forcing]\n",
    "            print(f'    Temperature anomaly: {self.state[config][0]}ยบC')\n",
    "            print(f'    CO2 emissions: {self.state[config][1]} GtC')\n",
    "            print(f'    Sulfur emissions: {self.state[config][2]} MtS')\n",
    "            print(f'    CO2 concentration: {self.state[config][3]} ppm')\n",
    "            print(f'    Radiative forcing: {self.state[config][4]} W/m2')\n",
    "        else:\n",
    "            print(\"No state initialized; call reset. \")\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        #should not call step without calling reset()\n",
    "        if(not self.state): #has not been initialized\n",
    "            self.reset()\n",
    "    \n",
    "        config = self.model.configs[1] #intervention\n",
    "        old_state = self.state[config] #save for reward function\n",
    "        year = self.t\n",
    "        done = False\n",
    "        \n",
    "        \n",
    "        # change emissions by action[0] from the previous year\n",
    "        # emit action amount additional sulfur within same year\n",
    "        new_emissions = self.model.emissions\n",
    "        emit_C = max(new_emissions.loc[self.t-0.5, self.model.scenarios[0], config, 'CO2 FFI'].item() + action[0], 0)\n",
    "        emit_S = new_emissions.loc[self.t+0.5, self.model.scenarios[0], config, 'Sulfur'] + action[1]\n",
    "        \n",
    "        new_emissions.loc[self.t+0.5, self.model.scenarios[0], config, 'CO2 FFI'] = emit_C\n",
    "        new_emissions.loc[self.t+0.5, self.model.scenarios[0], config, 'Sulfur'] = emit_S\n",
    "        \n",
    "        \n",
    "        # run model simulation with new values\n",
    "        #state is [year, temp, emit_c, emit_s, conc_c, forcing]\n",
    "        self.update_state(new_emissions) #CAUTION! self.t has now changed\n",
    "        \n",
    "        #Implementation of S, Y and Y_cost\n",
    "        Y[year] = beta * Y[year-1] # assume constant GDP growth of beta percent\n",
    "        \n",
    "        emission_cost = GtC_reduce_cost * (old_state[1] - self.state[config][1])\n",
    "        Y_cost[year] = (10/5 * self.state[config][0] - 2)/100 * Y[year] + self.aerosol_cost(action[1]) + emission_cost\n",
    "        \n",
    "        # gamma = 1 / ( 1+(S[year-1]/sigma)**rho )\n",
    "        #S[year] = S[year-1] + ( (1-gamma)*Y[year-1]/epsilon - S[year-1]/tau_S ) # not used in this implementation\n",
    "        \n",
    "        # fail if temperature error\n",
    "        if math.isnan(self.state[config][0]):\n",
    "            done = True\n",
    "        \n",
    "        \n",
    "        cur_fease = emit_C - self.ssp_370[self.ssp_370['Year']==year]['CO2-fossil (GtC/yr)'].squeeze() # positive if emitted more than default, otherwise negative\n",
    "        Y[year] = Y[year] - Y_cost[year] # update GDP to reflect cost of climate change\n",
    "        \n",
    "        #compute the reward\n",
    "        reward = self.reward_func(old_state, self.state[config], year, Y[year], Y_cost[year], cur_fease)\n",
    "        \n",
    "\n",
    "        # end the trial once 2100 is reached or if temp anomaly above 4 degrees\n",
    "        if self.t == self.end_year or self.state[config][0] > 4: # only runs to 2100\n",
    "            done = True\n",
    "        \n",
    "        observation = self.state[self.model.configs[1]]\n",
    "        \n",
    "        return observation, reward, done, {}\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d12a26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_model = model_reset()\n",
    "env = Simulator(reward_mode=simple_temp_reward, max_carbon=40, clim_model=cli_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cc3adcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samart/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/stable_baselines3/common/env_checker.py:286: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a391c184",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.543795981678114,\n",
       " 40.930383162101755,\n",
       " 79.96634301235318,\n",
       " 420.93987180697025,\n",
       " 2.951928296397111]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def access_state(model, year):\n",
    "    return([\n",
    "        year, \n",
    "        model.temperature.loc[year, model.scenarios[0], model.configs[1], 0].item(),\n",
    "        model.emissions.loc[year - 0.5, model.scenarios[0], model.configs[1], :][:2].sum().item(),\n",
    "        model.emissions.loc[year - 0.5, model.scenarios[0], model.configs[1], 'Sulfur'].item(),\n",
    "        model.concentration.loc[year, model.scenarios[0], model.configs[1], 'CO2'].item(),\n",
    "        model.forcing_sum.loc[year, model.scenarios[0], model.configs[1]].item()\n",
    "    ])\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e36acdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Year: 2023\n",
      "Without intervention:\n",
      "    Temperature anomaly: 1.6639810013301723ยบC\n",
      "    CO2 emissions: 41.21323642769785 GtC\n",
      "    Sulfur emissions: 79.85157962172558 MtS\n",
      "    CO2 concentration: 423.79606913089515 ppm\n",
      "    Radiative forcing: 3.031367280242108 W/m2\n",
      "\n",
      "With intervention:\n",
      "    Temperature anomaly: 1.6639810013301723ยบC\n",
      "    CO2 emissions: 41.21323642769785 GtC\n",
      "    Sulfur emissions: 79.85157962172558 MtS\n",
      "    CO2 concentration: 423.79606913089515 ppm\n",
      "    Radiative forcing: 3.031367280242108 W/m2\n",
      "\n",
      "\n",
      "Current Year: 2028\n",
      "Without intervention:\n",
      "    Temperature anomaly: 1.6215542701643095ยบC\n",
      "    CO2 emissions: 42.62750275567836 GtC\n",
      "    Sulfur emissions: 79.27776266858751 MtS\n",
      "    CO2 concentration: 438.4532554041039 ppm\n",
      "    Radiative forcing: 3.2011314753735647 W/m2\n",
      "\n",
      "With intervention:\n",
      "    Temperature anomaly: 1.4213736952901783ยบC\n",
      "    CO2 emissions: 2.9947906777113733 GtC\n",
      "    Sulfur emissions: 115.35874487683947 MtS\n",
      "    CO2 concentration: 418.6839006517718 ppm\n",
      "    Radiative forcing: 2.670223914717849 W/m2\n",
      "\n",
      "\n",
      "Current Year: 2033\n",
      "Without intervention:\n",
      "    Temperature anomaly: 1.7263392952969903ยบC\n",
      "    CO2 emissions: 43.63143004823285 GtC\n",
      "    Sulfur emissions: 76.44701070437473 MtS\n",
      "    CO2 concentration: 454.01038230753875 ppm\n",
      "    Radiative forcing: 3.4188584725772744 W/m2\n",
      "\n",
      "With intervention:\n",
      "    Temperature anomaly: 1.436878768753271ยบC\n",
      "    CO2 emissions: 2.737971364209658 GtC\n",
      "    Sulfur emissions: 109.50526876101536 MtS\n",
      "    CO2 concentration: 415.24437495649795 ppm\n",
      "    Radiative forcing: 2.664624533562859 W/m2\n",
      "\n",
      "\n",
      "Current Year: 2038\n",
      "Without intervention:\n",
      "    Temperature anomaly: 2.056983987354709ยบC\n",
      "    CO2 emissions: 44.01984878764832 GtC\n",
      "    Sulfur emissions: 70.23085622354985 MtS\n",
      "    CO2 concentration: 469.9356790796424 ppm\n",
      "    Radiative forcing: 3.72217742953893 W/m2\n",
      "\n",
      "With intervention:\n",
      "    Temperature anomaly: 1.6750930377205038ยบC\n",
      "    CO2 emissions: 2.379434139340528 GtC\n",
      "    Sulfur emissions: 76.26024798914433 MtS\n",
      "    CO2 concentration: 415.1543163346176 ppm\n",
      "    Radiative forcing: 2.9836839933987047 W/m2\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.303030729293823"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "s = time.time()\n",
    "for i in range(20):\n",
    "    state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    if(i%5==0):\n",
    "        env.render()\n",
    "        print(\"\\n\")\n",
    "    if(done):\n",
    "        print(\"Finished at \", i)\n",
    "        break\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bb535728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3858780860900879"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "env.step([0,0])\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4a68a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Simulator at 0x196e1ee60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81ff6f0",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77645ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.logger import configure\n",
    "import stable_baselines3\n",
    "from stable_baselines3 import PPO, DDPG, A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aeb002fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'name' : \"basic_test_2\",\n",
    "    'directory' : \"Experiment_1\", #the path in which the run will be saved\n",
    "    'max_carbon' : 36,\n",
    "    'max_sulfur' : 100,\n",
    "    'reward_mode' : \"simple_temp_reward\",\n",
    "    'scenario' : \"ssp245\",\n",
    "    'current_year' : 2023,\n",
    "    'end_year' : 2104,\n",
    "    \n",
    "    'algorithm' : \"a2c\",\n",
    "    'learning_rate' : 2.1e-04,\n",
    "    'gamma' : 0.9, \n",
    "    'device' : 'cpu',\n",
    "    'iterations' : 1000, \n",
    "    \"n_steps\" : 5,\n",
    "    'verbose' : 1,\n",
    "    'log_freq' : 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fc814a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dirs(args):\n",
    "    save_path = os.path.join(\"outputs\", args['directory'])\n",
    "    dirs = ['plots', 'logs', 'saved_models', 'evals']\n",
    "    for direc in dirs:\n",
    "        path = os.path.join(save_path, direc)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    \n",
    "    # save args configs\n",
    "    with open(os.path.join(save_path, args['name']+'_config.txt'), 'w') as file:\n",
    "        json.dump(args, file, indent=2)\n",
    "    \n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "72d52726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(args, climate_model = model_reset(), env_type=Simulator):\n",
    "    save_path = setup_dirs(args)\n",
    "    \n",
    "    env = env_type(reward_mode=args['reward_mode'], max_carbon=args['max_carbon'], max_aerosol=args['max_sulfur'],\n",
    "        clim_model=climate_model, scenario=args['scenario'], current_year=args['current_year'], end_year=args['end_year'])\n",
    "    \n",
    "    env.reset()\n",
    "    \n",
    "    model_builder = eval(args['algorithm'].upper()) # import from stable baselines\n",
    "    model = model_builder(\n",
    "        policy=\"MlpPolicy\",\n",
    "        env=env,\n",
    "        learning_rate = args['learning_rate'],\n",
    "        n_steps = args['n_steps'],\n",
    "        gamma= args['gamma'],\n",
    "        verbose=args['verbose'],\n",
    "        tensorboard_log=os.path.join(save_path, 'logs', args['name']),\n",
    "    )\n",
    "\n",
    "    model.set_logger(configure(\n",
    "        os.path.join(save_path, 'logs', args['name']),\n",
    "        [\"csv\", \"tensorboard\"]\n",
    "    ))\n",
    "    \n",
    "    return model, save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f942d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, save_path, args):\n",
    "    \n",
    "    model.learn(\n",
    "        total_timesteps=args['iterations'],\n",
    "        log_interval=args['log_freq'],\n",
    "        eval_log_path=os.path.join(save_path, 'logs', args['name']), #eval_freq=20,\n",
    "    )\n",
    "    \n",
    "    saved_path = os.path.join(os.path.join(save_path, 'saved_models'), args['name'])\n",
    "    model.save(saved_path)\n",
    "    \n",
    "    return saved_path, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7054d46b",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b92d045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state: [temp, co2_emit, sulfur_emit, co2_conc, forcing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2863ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Training code ####\n",
    "\n",
    "VARS = ['Year', 'Temperature Anomaly (ยฐC)', 'CO2 Emitted (GtC/yr)', 'Sulfur Emitted (MtS/yr)', 'CO2 Concentration (ppm)', 'ERF (W/m2)', 'Reward']\n",
    "\n",
    "def evaluate_model(args, test_iters=100, climate_model= model_reset(), env_class=Simulator, debug=False):\n",
    "    save_path = os.path.join(\"outputs\", args['directory'])\n",
    "    model_path = os.path.join(save_path, 'saved_models', args['name'])\n",
    "    \n",
    "    if(debug):\n",
    "        print(\"Model at \", model_path)\n",
    "    \n",
    "    env = env_class(reward_mode=args['reward_mode'], max_carbon=args['max_carbon'], max_aerosol=args['max_sulfur'],\n",
    "        clim_model=climate_model, scenario=args['scenario'], current_year=args['current_year'], end_year=args['end_year'])\n",
    "    \n",
    "    model = eval(args['algorithm'].upper()).load(model_path)\n",
    "    progress = pd.read_csv(os.path.join(save_path, \"logs/progress.csv\"))\n",
    "    \n",
    "    obs = env.reset()\n",
    "    def_vals = []\n",
    "    intervention_vals = []\n",
    "    for i in range(test_iters):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        if(debug and i%10==0):\n",
    "            print(\"Obs: \", obs)\n",
    "            print(\"action: \", action, '\\n')\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        state = env.access_state()\n",
    "        \n",
    "        if(debug and reward>10000):\n",
    "            print('Investigating sus reward at timestep ', i, \" \", reward)\n",
    "            env.render()\n",
    "            print(\"GDP and GDP Cost:\", Y.loc[state['Year']]/1e12, Y_cost.loc[state['Year']]/1e11)\n",
    "            break\n",
    "        \n",
    "        def_vals.append([state['Year']] + state[env.model.configs[0]] + [reward]) # get values for default and for intervention for comparison\n",
    "        intervention_vals.append([state['Year']] + state[env.model.configs[1]] + [reward])\n",
    "        \n",
    "        if(i%25==0):\n",
    "            print(\"Iteration number: \", i)\n",
    "        \n",
    "        if done:\n",
    "            print(\"\\n\\nSimulation concluded at iteration: \", i)\n",
    "            print(env.t)\n",
    "            env.render()\n",
    "            env.reset()\n",
    "            break;\n",
    "    \n",
    "    if(env.close is not None):\n",
    "        env.close()\n",
    "    \n",
    "    \n",
    "    return model, pd.DataFrame(data=intervention_vals, columns=VARS), pd.DataFrame(data=def_vals, columns=VARS), progress\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b75cc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output useful plots\n",
    "def make_plots(aero_vals, def_vals, save_path):\n",
    "    print(type(eval(\"aero_vals\")))\n",
    "    aero_vals.to_csv(os.path.join(save_path, 'evals', args['name']+\"_intervention.csv\"))\n",
    "    def_vals.to_csv(os.path.join(save_path, 'evals',args['name']+\"_default.csv\"))\n",
    "    \n",
    "    \n",
    "    plots_path = os.path.join(save_path, 'plots', args['name'])\n",
    "    if not os.path.exists(plots_path):\n",
    "        os.makedirs(plots_path)\n",
    " \n",
    "    \n",
    "    for col in aero_vals.columns[1:]:\n",
    "        plt.plot(aero_vals['Year'], aero_vals[col], label='geoengineering')\n",
    "        plt.plot(def_vals['Year'], def_vals[col], label='default')\n",
    "        plt.ylabel(col)\n",
    "        plt.xlabel('Year')\n",
    "        plt.legend(loc='upper left')\n",
    "        try:\n",
    "            plt.savefig(os.path.join(plots_path, col[:col.index(\"(\")-1]))\n",
    "        except ValueError:\n",
    "            plt.savefig(os.path.join(plots_path, col))\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a709a41",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "98562e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_temp_reward(old_state, state, year, GDP, GDP_cost, cur_fease):\n",
    "    # positive reward for temp under 1.5 goal\n",
    "    cur_temp = state[0]\n",
    "    \"\"\"if cur_temp > 3.5:\n",
    "        return -100\"\"\"\n",
    "    return 100*(1.5 - state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "738c482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'name' : \"exp_1_basic_test_ppo\",\n",
    "    'directory' : \"Experiment_1/run2\", #the path in which the run will be saved\n",
    "    'max_carbon' : 36,\n",
    "    'max_sulfur' : 100,\n",
    "    'reward_mode' : \"simple_temp_reward\",\n",
    "    'scenario' : \"ssp245\",\n",
    "    'current_year' : 2023,\n",
    "    'end_year' : 2104,\n",
    "    \n",
    "    'algorithm' : \"ppo\",\n",
    "    'learning_rate' : 2.1e-02,\n",
    "    'gamma' : 0.9, \n",
    "    'device' : 'cpu',\n",
    "    'iterations' : 150, \n",
    "    \"n_steps\" : 4,\n",
    "    'verbose' : 1,\n",
    "    'log_freq' : 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5aac31b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Runtime:  0.38005614280700684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samart/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:151: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 4`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 4\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=4 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRuntime: \u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m s)\n\u001b[1;32m      6\u001b[0m s \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 7\u001b[0m saved_path, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m s\n",
      "Cell \u001b[0;32mIn[86], line 3\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, save_path, args)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(model, save_path, args):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_freq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#eval_freq=20,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     saved_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_models\u001b[39m\u001b[38;5;124m'\u001b[39m), args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(saved_path)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:317\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m: PPOSelf,\n\u001b[1;32m    305\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PPOSelf:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:262\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    258\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 262\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:181\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, gym\u001b[38;5;241m.\u001b[39mspaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[1;32m    179\u001b[0m     clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 181\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 43\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     47\u001b[0m             \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(reward)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "Cell \u001b[0;32mIn[18], line 165\u001b[0m, in \u001b[0;36mSimulator.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    160\u001b[0m new_emissions\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mscenarios[\u001b[38;5;241m0\u001b[39m], config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSulfur\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m emit_S\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# run model simulation with new values\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m#state is [year, temp, emit_c, emit_s, conc_c, forcing]\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_emissions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#CAUTION! self.t has now changed\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m#Implementation of S, Y and Y_cost\u001b[39;00m\n\u001b[1;32m    168\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m ( \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39m(S[year\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39msigma)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrho )\n",
      "Cell \u001b[0;32mIn[18], line 68\u001b[0m, in \u001b[0;36mSimulator.update_state\u001b[0;34m(self, emissions)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, emissions):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43memissions\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# state is [year, temp, co2_emit, sulfur_emit, co2_conc, forcing]   \u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# state refers to at the conclusion of year X, all variables. At end, we are at beginning of year X+1\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt,\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfigs[\u001b[38;5;241m0\u001b[39m] : [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m         ]\n\u001b[1;32m     87\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[18], line 99\u001b[0m, in \u001b[0;36mSimulator.forward_func\u001b[0;34m(self, emissions)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model_reset()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39memissions \u001b[38;5;241m=\u001b[39m emissions\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/fair/fair.py:1903\u001b[0m, in \u001b[0;36mFAIR.run\u001b[0;34m(self, progress, suppress_warnings)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;66;03m# 15. sum forcings\u001b[39;00m\n\u001b[1;32m   1898\u001b[0m forcing_sum_array[i_timepoint \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m : i_timepoint \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnansum(\n\u001b[1;32m   1899\u001b[0m     forcing_array[i_timepoint \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m : i_timepoint \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], axis\u001b[38;5;241m=\u001b[39mSPECIES_AXIS\n\u001b[1;32m   1900\u001b[0m )\n\u001b[1;32m   1901\u001b[0m forcing_efficacy_sum_array[\n\u001b[1;32m   1902\u001b[0m     i_timepoint \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m : i_timepoint \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m-> 1903\u001b[0m ] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnansum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforcing_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi_timepoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_timepoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforcing_efficacy_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSPECIES_AXIS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[38;5;66;03m# 16. forcing to temperature\u001b[39;00m\n\u001b[1;32m   1910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_routine_flags[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mnansum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:722\u001b[0m, in \u001b[0;36mnansum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_nansum_dispatcher)\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnansum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m    625\u001b[0m            initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    Return the sum of array elements over a given axis treating Not a\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m    Numbers (NaNs) as zero.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    720\u001b[0m \n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m     a, mask \u001b[38;5;241m=\u001b[39m \u001b[43m_replace_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[1;32m    724\u001b[0m                   initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:108\u001b[0m, in \u001b[0;36m_replace_nan\u001b[0;34m(a, val)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(a, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 108\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a, mask\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cli_model = model_reset()\n",
    "s = time.time()\n",
    "model, save_path = create_model(args, cli_model, Simulator)\n",
    "print(\"Runtime: \", time.time() - s)\n",
    "\n",
    "s = time.time()\n",
    "saved_path, model = train_model(model, save_path, args)\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71ea31a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<stable_baselines3.ppo.ppo.PPO at 0x1cf076470>,\n",
       " 'outputs/Experiment1_run2/saved_models/exp_1_basic_test_ppo')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, saved_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e65913ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model at  outputs/Experiment_1/run2/saved_models/exp_1_basic_test_ppo\n",
      "Obs:  [1.543795981678114, 40.930383162101755, 79.96634301235318, 420.93987180697025, 2.951928296397111]\n",
      "action:  [ 1.5393689 10.066471 ] \n",
      "\n",
      "Iteration number:  0\n",
      "Obs:  [1.7885518860538459, 54.693436997447165, 87.75671270039322, 456.7473337413918, 3.341518003743947]\n",
      "action:  [ 1.5393689 10.066471 ] \n",
      "\n",
      "Obs:  [2.3787176483688537, 69.27541920212778, 75.24741203113116, 507.3495457938985, 4.047631225786898]\n",
      "action:  [ 1.5393689 10.066471 ] \n",
      "\n",
      "Iteration number:  25\n",
      "Obs:  [2.8059797114220943, 82.96797001708428, 62.635690507258694, 574.2184395030838, 4.860642561694877]\n",
      "action:  [ 1.539369 10.066471] \n",
      "\n",
      "Obs:  [3.0164304765645267, 96.45778332649132, 55.65950263209874, 656.0239549281362, 5.663765550447902]\n",
      "action:  [ 1.5393689 10.066471 ] \n",
      "\n",
      "Obs:  [3.5922913139195733, 111.12871051113405, 51.64010571810771, 756.9369371881456, 6.537176324629604]\n",
      "action:  [ 1.5393689 10.066471 ] \n",
      "\n",
      "Iteration number:  50\n",
      "\n",
      "\n",
      "Simulation concluded at iteration:  58\n",
      "2082\n",
      "Current Year: 2081\n",
      "Without intervention:\n",
      "    Temperature anomaly: 3.125459986595896ยบC\n",
      "    CO2 emissions: 26.838373445574987 GtC\n",
      "    Sulfur emissions: 38.50579276002973 MtS\n",
      "    CO2 concentration: 590.9213274323563 ppm\n",
      "    Radiative forcing: 5.2178937314261455 W/m2\n",
      "\n",
      "With intervention:\n",
      "    Temperature anomaly: 4.113591000868046ยบC\n",
      "    CO2 emissions: 123.9154895314471 GtC\n",
      "    Sulfur emissions: 48.57226385988324 MtS\n",
      "    CO2 concentration: 864.3918496252463 ppm\n",
      "    Radiative forcing: 7.3883210413678375 W/m2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cli_model \u001b[38;5;241m=\u001b[39m model_reset()\n\u001b[0;32m----> 2\u001b[0m model, aero_vals, def_vals, progress_log \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcli_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 45\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(args, test_iters, climate_model, env_class, debug)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28mprint\u001b[39m(env\u001b[38;5;241m.\u001b[39mt)\n\u001b[1;32m     44\u001b[0m         env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m---> 45\u001b[0m         \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m;\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(env\u001b[38;5;241m.\u001b[39mclose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "Cell \u001b[0;32mIn[18], line 61\u001b[0m, in \u001b[0;36mSimulator.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model_reset()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_year \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memissions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfigs[\u001b[38;5;241m1\u001b[39m]])\n",
      "Cell \u001b[0;32mIn[18], line 68\u001b[0m, in \u001b[0;36mSimulator.update_state\u001b[0;34m(self, emissions)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, emissions):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43memissions\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# state is [year, temp, co2_emit, sulfur_emit, co2_conc, forcing]   \u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# state refers to at the conclusion of year X, all variables. At end, we are at beginning of year X+1\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt,\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfigs[\u001b[38;5;241m0\u001b[39m] : [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m         ]\n\u001b[1;32m     87\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[18], line 99\u001b[0m, in \u001b[0;36mSimulator.forward_func\u001b[0;34m(self, emissions)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model_reset()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39memissions \u001b[38;5;241m=\u001b[39m emissions\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/fair/fair.py:1554\u001b[0m, in \u001b[0;36mFAIR.run\u001b[0;34m(self, progress, suppress_warnings)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_timepoint \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m   1544\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_timepoints),\n\u001b[1;32m   1545\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m progress,\n\u001b[1;32m   1546\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_scenarios\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_configs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m projections in parallel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1547\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1548\u001b[0m ):\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_routine_flags[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mghg\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1551\u001b[0m         \u001b[38;5;66;03m# 1. alpha scaling\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m         alpha_lifetime_array[\n\u001b[1;32m   1553\u001b[0m             i_timepoint : i_timepoint \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ghg_indices\n\u001b[0;32m-> 1554\u001b[0m         ] \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_alpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# this timepoint\u001b[39;49;00m\n\u001b[1;32m   1555\u001b[0m \u001b[43m            \u001b[49m\u001b[43mairborne_emissions_array\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m                \u001b[49m\u001b[43mi_timepoint\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_timepoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ghg_indices\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# last timebound\u001b[39;49;00m\n\u001b[1;32m   1558\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcumulative_emissions_array\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m                \u001b[49m\u001b[43mi_timepoint\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_timepoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ghg_indices\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# last timebound\u001b[39;49;00m\n\u001b[1;32m   1561\u001b[0m \u001b[43m            \u001b[49m\u001b[43mg0_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ghg_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m            \u001b[49m\u001b[43mg1_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ghg_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m            \u001b[49m\u001b[43miirf_0_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ghg_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m            \u001b[49m\u001b[43miirf_airborne_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ghg_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m            \u001b[49m\u001b[43miirf_temperature_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ghg_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m            \u001b[49m\u001b[43miirf_uptake_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ghg_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcummins_state_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi_timepoint\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_timepoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miirf_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;66;03m# 2. multi-species methane lifetime if desired; update GHG concentration\u001b[39;00m\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;66;03m# for CH4\u001b[39;00m\n\u001b[1;32m   1573\u001b[0m         \u001b[38;5;66;03m# needs previous timebound but this is no different to the generic\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mch4_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthornhill2021\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLforEE/lib/python3.10/site-packages/fair/gas_cycle/__init__.py:8\u001b[0m, in \u001b[0;36mcalculate_alpha\u001b[0;34m(airborne_emissions, cumulative_emissions, g0, g1, iirf_0, iirf_airborne, iirf_temperature, iirf_uptake, temperature, iirf_max)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_alpha\u001b[39m(\n\u001b[1;32m      9\u001b[0m     airborne_emissions,\n\u001b[1;32m     10\u001b[0m     cumulative_emissions,\n\u001b[1;32m     11\u001b[0m     g0,\n\u001b[1;32m     12\u001b[0m     g1,\n\u001b[1;32m     13\u001b[0m     iirf_0,\n\u001b[1;32m     14\u001b[0m     iirf_airborne,\n\u001b[1;32m     15\u001b[0m     iirf_temperature,\n\u001b[1;32m     16\u001b[0m     iirf_uptake,\n\u001b[1;32m     17\u001b[0m     temperature,\n\u001b[1;32m     18\u001b[0m     iirf_max,\n\u001b[1;32m     19\u001b[0m ):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Calculate greenhouse-gas time constant scaling factor.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m        scaling factor for lifetimes\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     iirf \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m         iirf_0\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;241m+\u001b[39m iirf_uptake \u001b[38;5;241m*\u001b[39m (cumulative_emissions \u001b[38;5;241m-\u001b[39m airborne_emissions)\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;241m+\u001b[39m iirf_temperature \u001b[38;5;241m*\u001b[39m temperature\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;241m+\u001b[39m iirf_airborne \u001b[38;5;241m*\u001b[39m airborne_emissions\n\u001b[1;32m     66\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cli_model = model_reset()\n",
    "model, aero_vals, def_vals, progress_log = evaluate_model(args, 100, cli_model, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "09da99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts = [3.9, 42, 84, 480, 4.2]\n",
    "#sts = env.state['intervention']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0dc1f268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7906537, 9.522955 ], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "86aecc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.      , 20.069826], dtype=float32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sts, deterministic=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4656e7e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m done\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43menv2\u001b[49m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;129;01mnot\u001b[39;00m done \u001b[38;5;129;01mand\u001b[39;00m reward\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m99\u001b[39m):\n\u001b[1;32m      4\u001b[0m     obs, reward, done, _ \u001b[38;5;241m=\u001b[39m env2\u001b[38;5;241m.\u001b[39mstep(model\u001b[38;5;241m.\u001b[39mpredict(env\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintervention\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env2' is not defined"
     ]
    }
   ],
   "source": [
    "done= False\n",
    "env2 = Simulator(reward_mode=args['reward_mode'], max_carbon=args['max_carbon'], max_aerosol=args['max_sulfur'],\n",
    "        clim_model=model_reset(), scenario=args['scenario'], current_year=args['current_year'], end_year=args['end_year'])\n",
    "obs = env2.reset()\n",
    "while(not done and reward<-99):\n",
    "    obs, reward, done, _ = env2.step(model.predict(obs)[0])\n",
    "    obs2, reward2, done2, _ = env2.step(model2.predict(env.state['intervention'])[0])\n",
    "    print(reward, reward2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be88ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e579ec5d",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19061b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b5790852",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'name': 'basic_test_PPO_1',\n",
    "    'directory': 'Experiment_2/run2',\n",
    "    'max_carbon': 40,\n",
    "    'max_sulfur': 100,\n",
    "    'reward_mode': 'carbon_cost_GDP_reward',\n",
    "    'scenario': 'ssp245',\n",
    "    'current_year': 2023,\n",
    "    'end_year': 2104,\n",
    "    'algorithm': 'a2c',\n",
    "    'learning_rate': 0.021,\n",
    "    'gamma': 0.8,\n",
    "    'device': 'cpu',\n",
    "    'iterations': 1000,\n",
    "    'n_steps': 4,\n",
    "    'verbose': 1,\n",
    "    'log_freq': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "69871067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carbon_cost_GDP_reward(old_state, state, year, GDP, GDP_cost, cur_fease):\n",
    "    cur_temp = state[0]\n",
    "    beta = 100 if cur_fease < 0 else 1\n",
    "    reward = beta * cur_fease\n",
    "    alpha = 1000 if cur_temp > 2 else 200\n",
    "    reward += alpha * (2-cur_temp)  \n",
    "    reward += GDP/1e12\n",
    "    reward -= GDP_cost/1e11\n",
    "    \n",
    "    if(reward>10000):\n",
    "        print(\"From inside reward function, reward: \", reward)\n",
    "        print('fease', cur_fease, \"temp: \", alpha * (2-cur_temp), 'GDP: ', GDP/1e12)\n",
    "        \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28337772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = model_reset()\n",
    "cm.timepoints.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d1bf99c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "climate_model = model_reset()\n",
    "model, save_path = create_model(args, climate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ff734caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383.51038098335266"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "saved_path, model = train_model(model, save_path, args)\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = model.get_env().observation_space.sample()\n",
    "model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0906dd20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cli_model = model_reset()\n",
    "model, aero_vals, def_vals, progress_log = evaluate_model(args, 100, cli_model, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1cd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(aero_vals, def_vals, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026cc919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "367f3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_state, state, year, GDP, GDP_cost, feasibility = [3.0694649911534575, 17.420316082341294, 30.63045035447857, 573.8355430312943, 5.12785451049449], [3.1587730143344377, 17.31498791362379, 30.438506811545007, 574.8772667983744, 5.133423717111619], 2103, 87557664071029.4, 3950925473782.9478, 0.3083147693868753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9a25038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1079.8931280625502"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carbon_cost_GDP_reward(old_state, state, year, GDP, GDP_cost, feasibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa215b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLforEE",
   "language": "python",
   "name": "mlforee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
